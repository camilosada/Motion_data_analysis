{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitbasecondadbd63e3006f6496f9e4024d92b65070b",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# percentil 80 20   SignalStatistics2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"df = df[df['Number of Occupants'] < df['Number of Occupants'].quantile(.999)]\\ndf = df[df['Number of Floors'] < df['Number of Floors'].quantile(.999)]\\ndf = df[df['Floor Area [ft2]'] < df['Floor Area [ft2]'].quantile(.999)]\\n\\ndf = df[(df['Country']=='US') | (df['Country']=='CA')]\""
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "# loading metadata file\n",
    "filePath = '/'\n",
    "df = dd.read_csv(filePath + '.csv').drop_duplicates()\n",
    "\n",
    "# Pre-processing to filter out inconsistent data\n",
    "df = df[df['Number of Remote Sensors'] < df['Number of Remote Sensors'].quantile(.999)]\n",
    "df = df[df['Number of Occupants'] < df['Number of Occupants'].quantile(.999)]\n",
    "df = df[df['Number of Floors'] < df['Number of Floors'].quantile(.999)]\n",
    "df = df[df['Floor Area [ft2]'] < df['Floor Area [ft2]'].quantile(.999)]\n",
    "\n",
    "df = df[(df['Country']=='US') | (df['Country']=='CA')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "lista = []\n",
    "# List all files in directory using pathlib\n",
    "path1=1/\"\n",
    "basepath = Path(path1)\n",
    "files_in_basepath = (entry for entry in basepath.iterdir() if entry.is_file())\n",
    "for item in files_in_basepath:\n",
    "    lista.append(item.name)\n",
    "path2=\"2/\"\n",
    "basepath = Path(path2)\n",
    "files_in_basepath = (entry for entry in basepath.iterdir() if entry.is_file())\n",
    "for item in files_in_basepath:\n",
    "    lista.append(item.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_FileName = [s.replace('.csv', '') for s in lista]  # to have only the name of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset with only Identifiers in 2019 \n",
    "df_in_2019 = df[df.Identifier.isin(lista_FileName)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of datasets for 1 and 2 occupants\n",
    "df1 = df_in_2019[(df_in_2019['Number of Occupants'] == 1 ) & (df_in_2019['Number of Remote Sensors'] >= 3)]\n",
    "df2 = df_in_2019[(df_in_2019['Number of Occupants'] == 2 ) & (df_in_2019['Number of Remote Sensors'] >= 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to have identifiers that are in the percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_percentilID1 = pd.read_csv('.csv')\n",
    "df_percentilID2 = pd.read_csv('.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid data\n",
    "df1=dd.merge(df1, df_percentilID1['0'], left_on='Identifier',right_on='0')\n",
    "df2=dd.merge(df2, df_percentilID2['0'], left_on='Identifier',right_on='0')\n",
    "\n",
    "# excluded from valid data\n",
    "#df1=df1[(~df1.Identifier.isin(df_percentilID1['0']))]\n",
    "#df2=df2[(~df2.Identifier.isin(df_percentilID2['0']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.sample(frac=(len(df1)/len(df2)), random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df2[(~df2.Identifier.isin(df2_aa.Identifier.compute()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all Identifiers of df2, to after open them\n",
    "a=df2.loc[:,'Identifier'].compute().tolist()\n",
    "lista=[]\n",
    "for i in a:\n",
    "    lista.append(mainPath+i+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "642"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "len(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all files in the df2['Identifier'] column\n",
    "ff=dd.read_csv(lista,  parse_dates=['DateTime'], include_path_column=True).drop('Unnamed: 0',axis=1)\n",
    "ff['path']=ff['path'].str.replace(path2, '')\n",
    "ff['path']=ff['path'].str.replace('.csv', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manage of columns\n",
    "\n",
    "ff['dayofweek']=ff['DateTime'].dt.day_name()\n",
    "ff['Time'] = ff['DateTime'].dt.time\n",
    "ff['Month'] = ff['DateTime'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_columns = ['path', 'mean_activation', 'dayofweek', 'Time', 'Month']\n",
    "result = dd.merge(df2[['Identifier','Number of Remote Sensors']], ff[ff_columns], left_on='Identifier', right_on='path').drop(['path'],axis=1)\n",
    "#result['mean_activation']=result['activation']/(result['working_sensors']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=result[['Identifier','dayofweek','Time','mean_activation']].groupby(['Identifier','Time','dayofweek']).mean()\n",
    "pp=dd.from_array(aa.to_records()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp[\"TimeSTR\"]=pp[\"Time\"].apply((lambda x: x.strftime('%H:%M')), meta='str')\n",
    "aa2 = pp.copy()\n",
    "new = aa2[\"TimeSTR\"]\n",
    "  \n",
    "# concatenating team with name column \n",
    "# overwriting name column \n",
    "aa2[\"dayofweek\"]= aa2[\"dayofweek\"].str.cat(new, sep =\", \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bb=aa2.drop(['Time'],axis=1)\n",
    "bb = bb.categorize(columns='dayofweek')\n",
    "table = dd.pivot_table(bb, values='mean_activation', index='Identifier',\n",
    "                    columns='dayofweek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=dd.from_array(table.to_records())\n",
    "result_f = dd.merge(df2,t, on='Identifier').drop(['filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(result_f.compute()).to_csv('.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying seaborn std plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "filePath = '/'\n",
    "df_1ocupante = pd.read_csv(filePath + '.csv', index_col=0)\n",
    "df_2ocupantes = pd.read_csv(filePath + '.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1152, 2039)\n"
     ]
    }
   ],
   "source": [
    "seed=2020\n",
    "df_pp = pd.concat([df_1ocupante, df_2ocupantes])\n",
    "df_pp = df_pp.reset_index()\n",
    "\n",
    "# Drop data with missing values\n",
    "df_pp = df_pp.loc[df_pp.iloc[:, 22:].dropna().index]\n",
    "print(df_pp.shape)\n",
    "# Resample dataframe\n",
    "resample_value = df_pp['Number of Occupants'].value_counts().min()\n",
    "df_pp = pd.concat([\n",
    "    df_pp[df_pp['Number of Occupants'] == 1].sample(resample_value,random_state=seed),\n",
    "    df_pp[df_pp['Number of Occupants'] == 2].sample(resample_value,random_state=seed)\n",
    "])\n",
    "df_pp = df_pp.sample(frac=1,random_state=seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_df=df_pp.iloc[:, 22:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_df[['Number of Occupants','Identifier']] = df_pp[['Number of Occupants','Identifier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri=df_df.drop(['Identifier','0'],axis=1).melt(id_vars=[\"Number of Occupants\"], \n",
    "        var_name=\"Date\", \n",
    "        value_name=\"Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri1=fmri[fmri['Number of Occupants']==1]\n",
    "fmri2=fmri[fmri['Number of Occupants']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp1=fmri1.drop('Number of Occupants',axis=1).groupby(['Date']).describe(percentiles=[0.05, 0.95, 0.10,0.90,0.15,0.85,0.20,0.80])\n",
    "pp2=fmri2.drop('Number of Occupants',axis=1).groupby(['Date']).describe(percentiles=[0.05, 0.95, 0.10,0.90,0.15,0.85,0.20,0.80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"husl\", 1)\n",
    "colors = sns.color_palette(\"husl\", 2)\n",
    "#sns.lineplot(ax=ax,data=fmri1, x=\"Date\", y=\"Value\", hue=\"Number of Occupants\",ci=95,palette=palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,8))\n",
    "xtick= np.arange(start=0, stop=len(pp1.index), step=72)\n",
    "plt.xticks(rotation=90)\n",
    "plt.setp(ax, xticks=xtick, xticklabels=pp1.index[xtick])\n",
    "\n",
    "ax.set_title( 'Filter percentile 80-20, average activation of each day of the week every 5 minutes throughout the year')\n",
    "\n",
    "sns.lineplot(ax=ax,data=pp1['Value'][['mean']],palette=palette,legend=False)\n",
    "\n",
    "sns.lineplot(ax=ax,data=pp2['Value'][['mean']],legend=False)\n",
    "ax.legend(['One occupant','Two occupants'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,8))\n",
    "\n",
    "sns.lineplot(ax=ax,data=pp1['Value'][['mean']],palette=palette)\n",
    "ax.fill_between(pp1.index, y1=pp1['Value'][['5%']]['5%'], y2=pp1['Value'][['95%']]['95%'],alpha=0.2,facecolor=palette)#,alpha=0.40,  facecolor = colors)\n",
    "sns.lineplot(ax=ax,data=pp2['Value'][['mean']])\n",
    "ax.fill_between(pp2.index, y1=pp2['Value'][['5%']]['5%'], y2=pp2['Value'][['95%']]['95%'],alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}