{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitbasecondadbd63e3006f6496f9e4024d92b65070b",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from pathlib import Path\n",
    "import glob  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading metadata file\n",
    "filePath = '/'\n",
    "df = dd.read_csv(filePath + '.csv').drop_duplicates()\n",
    "\n",
    "# Pre-processing to filter out inconsistent data\n",
    "df = df[df['Number of Occupants'] < df['Number of Occupants'].quantile(.999)]\n",
    "df = df[df['Number of Floors'] < df['Number of Floors'].quantile(.999)]\n",
    "df = df[df['Floor Area [ft2]'] < df['Floor Area [ft2]'].quantile(.999)]\n",
    "df = df[df['Number of Remote Sensors'] < df['Number of Remote Sensors'].quantile(.999)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []\n",
    "# List all files in directory using pathlib\n",
    "basepath = Path(\"/\")\n",
    "files_in_basepath = (entry for entry in basepath.iterdir() if entry.is_file())\n",
    "for item in files_in_basepath:\n",
    "    lista.append(item.name)\n",
    "lista_FileName = [s.replace('.csv', '') for s in lista]  # to have only the name of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset with only Identifiers in 2019 \n",
    "df_in_2019 = df[df.Identifier.isin(lista_FileName)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of datasets for 1 and 2 occupants\n",
    "df1 = df_in_2019[(df_in_2019['Number of Occupants'] == 1 ) & (df_in_2019['Number of Remote Sensors'] >= 3)]\n",
    "df2 = df_in_2019[(df_in_2019['Number of Occupants'] == 4 ) & (df_in_2019['Number of Remote Sensors'] >= 3)] # dataframe with the data I want to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all Identifiers of df2, to after open them\n",
    "lista1=df2.loc[:,'Identifier'].compute().tolist()\n",
    "lista=[]\n",
    "for i in lista1:\n",
    "    lista.append(mainPath+i+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat=pd.DataFrame()\n",
    "\n",
    "for Idi in lista1:\n",
    "     \n",
    "    df_lista = pd.read_csv(mainPath + Idi+ '.csv', usecols = use_cols)\n",
    "\n",
    "    # perform data filtering \n",
    "    df_lista_2 = df_lista.loc[:, df_lista.columns.str.contains('_Motion')].fillna(0)\n",
    "    df_lista_2['DateTime']= df_lista['DateTime']\n",
    "    \n",
    "    df_lista_2['DateTime'] = pd.to_datetime(df_lista_2['DateTime'])\n",
    "    df_lista_2 = df_lista_2.set_index(['DateTime'])\n",
    "    \n",
    "    #sum motion\n",
    "    df_lista_2['activation'] = df_lista_2.loc[:, df_lista_2.columns.str.contains('_Motion')].sum(axis=1)\n",
    "    # rolling\n",
    "    df_resamble = pd.DataFrame(df_lista_2['activation'].rolling('10T').sum())\n",
    "    # shift\n",
    "    df_resamble['activation']=np.roll(df_resamble['activation'],-1)\n",
    "    # and logical\n",
    "    df_and = df_resamble*pd.DataFrame(df_lista_2['activation'] )\n",
    "    df_greater_1 = df_lista_2[df_and> 2].fillna(0)\n",
    "     \n",
    "    final_df = df_greater_1.drop(df_greater_1.loc[:, df_greater_1.columns.str.contains('_Motion')], axis=1)\n",
    "    final_df = pd.DataFrame(final_df.to_records())\n",
    "    final_df['path']= Idi # Add the identifier to know to what data it corresponds\n",
    "    final_df.to_csv('/'+Idi+ '.csv') # save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff=dd.read_csv('/*', parse_dates=['DateTime']).drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff['dayofweek']=ff['DateTime'].dt.day_name()\n",
    "ff['Time'] = ff['DateTime'].dt.time\n",
    "ff['Month'] = ff['DateTime'].dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_columns = ['path', 'activation', 'dayofweek', 'Time', 'Month']\n",
    "result = dd.merge(df2[['Identifier','Number of Remote Sensors']], ff[ff_columns], left_on='Identifier', right_on='path').drop(['path'],axis=1)\n",
    "result['mean_activation']=(result['activation']/(result['Number of Remote Sensors']))  \n",
    "result_group=result[['Identifier','dayofweek','Time','mean_activation']].groupby(['Identifier','Time','dayofweek']).mean()\n",
    "df_result_group=dd.from_array(result_group.to_records()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_group[\"TimeSTR\"]=df_result_group[\"Time\"].apply((lambda x: x.strftime('%H:%M')), meta='str')\n",
    "copy_df_result_group = df_result_group.copy()\n",
    "new = copy_df_result_group[\"TimeSTR\"]\n",
    "# concatenating Time with dayofweek column \n",
    "# overwriting name column \n",
    "copy_df_result_group[\"dayofweek\"]= copy_df_result_group[\"dayofweek\"].str.cat(new, sep =\", \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hace el mean de los valores de activation que coinciden para una misma posicion en la matriz\n",
    "df_bb=copy_df_result_group.drop(['Time'],axis=1)\n",
    "df_bb = df_bb.categorize(columns='dayofweek')\n",
    "table = dd.pivot_table(df_bb, values='mean_activation', index='Identifier',\n",
    "                    columns='dayofweek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=dd.from_array(table.to_records())\n",
    "result_f = dd.merge(df2,t, on='Identifier').drop(['filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(result_f.compute()).to_csv('.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}