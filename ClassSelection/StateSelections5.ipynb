{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('base': conda)",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1684057a43a35cb5b3002f49adb9822bc78eb18ff36df5d6d02aa26bbe725bc3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Selection of data from 2019 with at least 3 remote sensors, 1,2,3 or 4 occupants and from Florida or California"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "seed=2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1412, 22)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Import the data\n",
    "df1=pd.read_csv('F:/metadata/meta_data.csv')\n",
    "# Remove repeating rows and unrepresentative data\n",
    "df = df1.drop_duplicates()\n",
    "df = df[df['Number of Occupants'] < df['Number of Occupants'].quantile(.999)]\n",
    "df = df[df['Number of Floors'] < df['Number of Floors'].quantile(.999)]\n",
    "df = df[df['Floor Area [ft2]'] < df['Floor Area [ft2]'].quantile(.999)]\n",
    "df = df[df['Number of Remote Sensors'] < df['Number of Remote Sensors'].quantile(.999)]\n",
    "# Selection of useful data\n",
    "df=df[(df['Country']=='US') & ((df['ProvinceState']=='CA') | (df['ProvinceState']=='FL'))]\n",
    "df=df[df['Number of Remote Sensors'] >=3]\n",
    "df=df[(df['Number of Occupants']<=4) &  (df['Number of Occupants'] >0)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all 2019 files in directory using pathlib\n",
    "lista = []\n",
    "basepath = Path(\"/\")\n",
    "files_in_basepath = (entry for entry in basepath.iterdir() if entry.is_file())\n",
    "for item in files_in_basepath:\n",
    "    lista.append(item.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_FileName = [s.replace('.csv', '') for s in lista] \n",
    "df_in_2019 = df[df['Identifier'].isin(lista_FileName)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = df_in_2019[['Identifier','ProvinceState']].groupby('ProvinceState').count()\n",
    "ax_ProvinceState= group_df.plot(kind='bar',figsize=(9, 6))\n",
    "plt.xticks(rotation=0)\n",
    "ax_ProvinceState.set_title(\"Number of identifiers in each province in 2019 with at least 3 sensors\")\n",
    "ax_ProvinceState.set_xlabel('ProvinceState')\n",
    "ax_ProvinceState.set_ylabel('Number of Identifiers')\n",
    "\n",
    "rects_Country = ax_ProvinceState.patches # ubicacion de las barras del grafico \n",
    "\n",
    "y_value_Country = group_df['Identifier']\n",
    "labels_Country = y_value_Country # valores de altura de cada barra(valor en y)\n",
    "\n",
    "for rect, label in zip(rects_Country, labels_Country): # uno valor y ubicacion de cada barra para asignarselos uno a uno en el grafico con ax.text\n",
    "       height = rect.get_height()\n",
    "       ax_ProvinceState.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample dataframe\n",
    "resample_value = df_in_2019['ProvinceState'].value_counts().min()\n",
    "df_province1 = df_in_2019[df_in_2019['ProvinceState']=='CA'].sample(resample_value,random_state=seed)\n",
    "df_province2 = df_in_2019[df_in_2019['ProvinceState']=='FL'].sample(resample_value,random_state=seed)\n",
    "\n",
    "df_province_1_2 = pd.concat([\n",
    "    df_province1,\n",
    "    df_province2\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\"fig, axes = plt.subplots()\\n\\nx = np.arange(start=0, stop=20, step=5)  # the label locations\\nwidth = 0.4\\n\\naxes.bar(x-width/2, df_province1[\\'Number of Occupants\\'].values,width)\\naxes.bar(x+width/2, df_province2[\\'Number of Occupants\\'].values,width)\\ndf_province1.shape\"'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# \n",
    "'''\"fig, axes = plt.subplots()\n",
    "\n",
    "x = np.arange(start=0, stop=20, step=5)  # the label locations\n",
    "width = 0.4\n",
    "\n",
    "axes.bar(x-width/2, df_province1['Number of Occupants'].values,width)\n",
    "axes.bar(x+width/2, df_province2['Number of Occupants'].values,width)\n",
    "df_province1.shape\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = []\n",
    "mainPath =\n",
    "# Take all Identifiers of df_province_1_2, to after open them\n",
    "a=df_province_1_2.loc[:,'Identifier'].tolist()\n",
    "lista=[]\n",
    "for i in a:\n",
    "    lista.append(mainPath+i+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to open it with dask\n",
    "df_province_1_2.to_csv('sv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the data with Dask\n",
    "dd_province_1_2 = dd.read_csv('sv').drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all files in the df_province_1_2['Identifier'] column\n",
    "ff=dd.read_csv(lista, usecols = use_cols, parse_dates=['DateTime'], include_path_column=True)\n",
    "ff['path']=ff['path'].str.replace('/', '')\n",
    "ff['path']=ff['path'].str.replace('.csv', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manage of columns\n",
    "ff['activation'] = ff.loc[:, ff.columns.str.contains('_Motion')].sum(axis=1) # Sum of the number of RS in 1 in each row\n",
    "ff['dayofweek']=ff['DateTime'].dt.day_name()# Know what day of the week it is\n",
    "ff['Time'] = ff['DateTime'].dt.time\n",
    "#ff['Month'] = ff['DateTime'].dt.month\n",
    "\n",
    "ff_columns = ['path', 'activation', 'dayofweek', 'Time']#, 'Month']\n",
    "result = dd.merge(dd_province_1_2[['Identifier','Number of Remote Sensors']], ff[ff_columns], left_on='Identifier', right_on='path').drop(['path'],axis=1)\n",
    "result['mean_activation']=result['activation']/(result['Number of Remote Sensors']+1) # Normalization according to the number of sensors that each identifier has (+1 counting sensor of thermostat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by identifier, time and day of the week\n",
    "aa=result[['Identifier','dayofweek','Time','mean_activation']].groupby(['Identifier','Time','dayofweek']).mean()\n",
    "pp=dd.from_array(aa.to_records()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating Time with dayofweek \n",
    "pp[\"TimeSTR\"]=pp[\"Time\"].apply((lambda x: x.strftime('%H:%M')), meta='str')\n",
    "aa2 = pp.copy()\n",
    "new = aa2[\"TimeSTR\"]\n",
    "# overwriting name column \n",
    "aa2[\"dayofweek\"]= aa2[\"dayofweek\"].str.cat(new, sep =\", \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotating the table to have the time-day of the week as columns\n",
    "bb=aa2.drop(['Time'],axis=1)\n",
    "bb = bb.categorize(columns='dayofweek')\n",
    "table = dd.pivot_table(bb, values='mean_activation', index='Identifier',\n",
    "                    columns='dayofweek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=dd.from_array(table.to_records())\n",
    "result_f = dd.merge(dd_province_1_2,t, on='Identifier').drop(['filename'],axis=1) # Join to have the complete data of each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(result_f.compute()).to_csv('.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}